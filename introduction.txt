Spurious correlation is a common problem in machine learning models. Irrelevant correlation with the learning problem, also known as shortcuts, dataset biases, group robustness, and simplicity bias in some fields, is a correlation between features and the labels that can negatively impact the generalization and robustness of the models. As a result, the models will not work well with real-world data.Â 
Machine learning models are sensitive to spurious correlation because no single model is universally superior to solving different kinds of problems. Spurious correlation might happen due to imbalanced group labels, resulting in the majority being overrepresented and biased datasets that assumed incorrectly irrelevant patterns to be predictive (overfitting).
In order to solve the spurious correlation, optimization by Empirical Risk Minimization (ERM) is one of the options since the optimization does not take spurious attributes. If the assumption of availability of group information is held, worst-group training loss or reweighting can be optimized. Models that rely on spurious features will have poor worst-group accuracy, while model that rely on core features will have more uniform accuracy.
Several methods to address spurious correlation problems in machine learning models are: (1) data manipulation by modifying the input (new samples or auxiliary variables) of the algorithm to balance or diversify data; (2) representation learning that includes causal intervention, feature disentanglement, invariant learning, and contrastive learning; (3) learning strategies to choose correct optimization, ensemble learning, identification mitigation, fine-tuning strategy, or adversarial training; (4) other methods, such as multi-task problems, reinforcement learning, and Test-Time Adaptation.
In order to evaluate non-spurious features, decoding from the representations learned by standard Empirical Risk Minimization (ERM) and specialized group robustness training is necessary. Simple ERM is competitive with a specialized group robustness method targeted at reducing spurious correlation. Based on Deep Feature Reweighting (DFR), evaluation by only retraining the last layer on the held-out set where the spurious correlation is broken could be the solution. It is much simpler and more efficient in terms of training time.
The quality of learned feature representations is affected by design decisions beyond the training method, and strong regularization is not necessary for learning high-quality feature representations. Moreover, exploiting the predictive power of spurious can achieve strong average performance but perform poorly on sub-groups where spurious features do not hold.
Training a robust classifier can be divided into two tasks, which are extracting feature representations and training a linear classifier. The specialized group robustness method outperforms standard ERM, and it is highly competitive by applying DFR and giving better weighting in the last layer but not better representation of core features.
The most common metric to evaluate the model is the worst-group accuracy. Other metrics that were commonly used in the previous studies are the average of all group accuracy and bias-conflicting accuracy, which can be used together or separately. Linear dependence between in-distribution accuracy and worst-group accuracy implies good feature learning. The pre-training strategy has a significant effect, while strong regularization.
